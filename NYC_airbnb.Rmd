---
title: "Apprentissage Statistique"
subtitle: "New York city Airbnb"
subsubtitle: "RStudio version 1.2.5001 & R version 3.6.2 (2019-12-12)"
author: "Duong Nguyen & Julien Le Mauff"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document: default
---

```{r setup, include=F, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = T)
```

# Import Packages

```{r cache=TRUE,include=F,message=FALSE, warning=FALSE}
library(caret)
library(dplyr)
library(tidyr)
library(psych)
library(caret)
library(ggplot2)
library(ggmap)
library(lubridate)
library(stringr)
library(forcats)
library(foreach)
library(gridExtra)
library(vroom)
library(xgboost)
library(e1071)
library(kernlab)
library(corrplot)
library(doMC)
library(GGally)
```

# Import Raw data

```{r cache=TRUE,include=F,message=FALSE, warning=FALSE, eval=FALSE}
# Get the file names of every csv file with the pattern "listing_"
files <- fs::dir_ls(glob = "listing_*csv")

# Column we keep from the listings csv files
listings_keep <- c("id", "price", "state", "host_is_superhost",
                   "neighbourhood_group_cleansed", "neighbourhood_cleansed",
                   "latitude","longitude", "property_type", "accommodates",
                   "bedrooms", "beds", "bed_type", "cleaning_fee",
                   "minimum_nights", "availability_365",
                   "review_scores_rating","cancellation_policy")

# Import all the files and bind them together
listings <- vroom(files, col_select = listings_keep, delim= ",")

# Keep only observations with state == "NY"
listings <- listings[listings$state=="NY",]

# Drop state column
listings <- listings[ , !(names(listings) %in% c("state"))]

# Eliminate all duplicates listings
listings <- listings[!duplicated(listings$id),]

# Eliminate observations with missing id
listings <- listings[complete.cases(listings$id),]

# Eliminate the $ sign on price
listings$price = as.numeric(gsub("[\\$,]", "", listings$price))

# Eliminate the $ sign on cleaning fee
listings$cleaning_fee = as.numeric(gsub("[\\$,]", "", listings$cleaning_fee))

# Eliminate observations in which the id is non numeric
id_remove <- grep("[^0-9]",listings$id)
listings <- listings[-id_remove, ]

# Export the listing compiled database
write.csv(listings, "Data/data_compiled.csv", row.names = FALSE)
```

# Data manipulations / Cleaning the data

```{r cache=TRUE,include=F,message=FALSE, warning=FALSE, eval=FALSE}
data <- read.csv("/Users/ngyduong/Documents/Machine Learning/Github_projects/NewYork_Airbnb/NYC_Airbnb/Data/data_compiled.csv", sep = ",")
```

## Dealing with missing values

```{r cache=TRUE,include=F,message=FALSE, warning=FALSE, eval=FALSE}
# ===== ===== NA count ===== =====

na_count <- t(data %>% summarise_each(funs(sum(is.na(.)))))

# ===== ===== Check the class of each variables ===== =====

lapply(data,class)

# ===== ===== Price ===== ====

# For the sake of simplicity, we delete the observations where price is null

data <- data %>% filter(price > 0) 

# ===== ===== Bedrooms ===== =====

histogram(data$bedrooms)

# Given the distribution, we could replace the 112 missing values
# of bedrooms (the number of bedrooms) by the median grouped
# by property type, number of accomodates and bed types.

# We would use the median because we want an integer and not a float
# (numbers with commas). Furthermore, the median works great against 
# skewed distribution and outliers. 

data <- data %>%
  group_by(
    property_type,
    accommodates,
    bed_type) %>%
  mutate(bedrooms=ifelse(is.na(bedrooms),
                         median(bedrooms,na.rm = T),bedrooms)) %>%
  ungroup()

# ===== ===== Beds ===== =====

histogram(data$beds)

# Given the distribution, we could replace the 174 missing values
# of beds (the number of beds) by the median grouped
# by property type, number of accomodates and bed types

# We would use the median because we want an integer and not a float
# (numbers with commas). Furthermore, the median works great against 
# skewed distribution and outliers. 

data <- data %>%
  group_by(
    property_type,
    accommodates,
    bed_type) %>%
  mutate(beds=ifelse(is.na(beds),
                         median(beds,na.rm=T),beds)) %>%
  ungroup()

# ===== ===== Cleaning fee ===== =====

# A cleaning fee is a one-time fee charged by hosts to cover the cost of
# cleaning their holiday rental when guests depart. Not all hosts charge
# this fee. Some incorporate it into their nightly rate.

# Therefore it is safe to assume that when there is no value for this
# variable it simply means that the host didn't charge

data[is.na(data$cleaning_fee), "cleaning_fee"] <- 0

# ===== ===== Host is superhost ===== =====

# There is only 94 missing values out of more than 78 000
# Therefore we will just replace them by the most common value (f)

data[is.na(data$host_is_superhost),"host_is_superhost"] <- "f"

# ===== ===== Review scores rating ===== =====

histogram(data$review_scores_rating)

# Given that the distribution is skewed on the right, we will use the
# median to approximate the missing values grouped by neighbours,
# property types, type of beds and if the host is a superhost.

data <- data %>%
  group_by(neighbourhood_cleansed,
           bed_type,
           property_type,
           host_is_superhost) %>%
  mutate(review_scores_rating=ifelse(is.na(review_scores_rating), 
                                     median(review_scores_rating,na.rm=T),
                                     review_scores_rating)) %>%
  ungroup()

# There is still 363 missing values so we could just replace them with the
# overall score median or we remove them since we have enough observations

data[is.na(data$review_scores_rating), "review_scores_rating"] <-
  median(data$review_scores_rating, na.rm = T)

# ===== ===== Cancellation policy ===== =====

# There is only 1 missing values so we remove it

data <- data[complete.cases(data$cancellation_policy),]
```

## Dealing with categorical variables 

```{r cache=TRUE,include=F,message=FALSE, warning=FALSE, eval=FALSE}
# # ===== ===== Type de logement ===== =====

# We groups all 40 subgroups of logement types into 5 big groups

Appartment <- c("Aparthotel","Serviced apartment", "Loft",
                "Condominium", "Apartment")

House <- c("Barn", "Timeshare", "Dome house", "Lighthouse", "Houseboat",
           "Treehouse", "Earth house", "Cottage", "Tiny house",
           "Townhouse", "House", "Bungalow", "Cabin","Villa")

Shared_room <- c("Dorm", "Hostel", "Guesthouse", "Timeshare")

Private_room <- c("Farm stay", "Bed and breakfast", "Resort", "Hotel",
                  "Boutique hotel", "Guest suite", "In-law")

Other <- c("Train", "Bus", "Boat", "Other", "Cave", "Island",
           "Camper/RV", "Yurt", "Castle", "Tent", "Nature lodge",
           "Pension (South Korea)","Casa particular (Cuba)")

data$property_type <- as.character(data$property_type)

data <-
  mutate(data,
         property_type = ifelse(property_type %in% Appartment,
                                "Appartment", property_type),
         property_type = ifelse(property_type %in% House,
                                "House", property_type),
         property_type = ifelse(property_type %in% Shared_room,
                                "SharedRoom", property_type),
         property_type = ifelse(property_type %in% Private_room,
                                "PrivateRoom", property_type),
         property_type = ifelse(property_type %in% Other,
                                "Others", property_type))

data <- data[!data$property_type=="Others",]

# # ===== ===== Cancellation policy ===== =====

# We change from "t" to "Truee and "f" to False
data <- mutate(data, 
               host_is_superhost = ifelse(host_is_superhost=="t", 
                                          "True", "False"))

# # ===== ===== Host is superhost ===== =====

# We groups all 4 subgroups of strict types into only group

data$cancellation_policy <- as.character(data$cancellation_policy)

# We change from "t" to "Truee and "f" to False
data <- mutate(data, 
               cancellation_policy = 
                 ifelse(cancellation_policy=="strict_14_with_grace_period",
                        "strict", cancellation_policy),
               cancellation_policy =
                 ifelse(cancellation_policy=="super_strict_30", 
                        "strict", cancellation_policy),
               cancellation_policy =
                 ifelse(cancellation_policy=="super_strict_60", 
                        "strict", cancellation_policy))

# # ===== ===== Bed Types ===== =====

# data$bed_type <- as.character(data$bed_type)
# 
# # We change from "Pull-out Sofa" to "PullOut_Sofa" and "Real Bed" to "Real Bed"
# data <- mutate(data, 
#                bed_type = ifelse(bed_type=="Pull-out Sofa", 
#                                  "PullOut_Sofa", bed_type),
#                bed_type = ifelse(bed_type=="Real Bed",
#                                  "RealBed", bed_type))

# After more carefull decision we have decided to remove bed_type 
# Because out of more than 78000, only a handfull of 1014 observations
# have their bedtype value different from "Real Bed"

data <- data[,-which(names(data) == "bed_type")]

# # ===== ===== Borough (neighbourhood_group_cleansed) ===== =====

data$neighbourhood_group_cleansed <- as.character(data$neighbourhood_group_cleansed)

# We change from "Pull-out Sofa" to "PullOut_Sofa" and "Real Bed" to "Real Bed"
data <- mutate(data, 
               neighbourhood_group_cleansed = 
                 ifelse(neighbourhood_group_cleansed=="Staten Island", 
                        "StatenIsland", neighbourhood_group_cleansed))
```

```{r cache=TRUE,include=F,message=FALSE, warning=FALSE, eval=FALSE}
write.csv(data, "/Users/ngyduong/Documents/Machine Learning/Github_projects/NewYork_Airbnb/NYC_Airbnb/Data/clean_data.csv", row.names = FALSE) 
```
 
# Data analysis / Data visualisation

```{r cache=TRUE,include=F,message=FALSE, warning=FALSE, echo=T}
# Nguyen Duong
data <- read.csv("/Users/ngyduong/Documents/Machine Learning/Github_projects/NewYork_Airbnb/NYC_Airbnb/Data/clean_data.csv", sep = ",")

# Julien Le Mauff
# data <- read.csv("/Users/lemauffjulien/Documents/Documents/Master 2/S2/NYC_Airbnb/Data/clean_data.csv", sep = ",")

# As Factor
Asfactor = c("host_is_superhost", "neighbourhood_group_cleansed",
             "neighbourhood_cleansed", "property_type",
             "cancellation_policy")

for (i in Asfactor){
  data[,i] <- as.factor(data[,i])
}
```

## Data visualisation

```{r cache=TRUE,include=F,message=FALSE, warning=FALSE}
theme <- theme(plot.title = element_text(hjust = 0.5),
               plot.background = element_rect(fill = "#BFD5E3"))
tag_source <- "Source: Inside Airbnb"
```

### Frequence of discrete variables

```{r cache=TRUE,include=T,message=FALSE, warning=FALSE, echo=T}
names <- names(data)

data <- data %>% rename(arrondissement = neighbourhood_group_cleansed, 
                        type_de_propriété = property_type,
                        politique_annulation = cancellation_policy)

features_discrete <- names(select_if(data[,-c(1,5)],is.factor))
# Without id, neighbourhood_group_cleansed

for (i in features_discrete) {
  plot <-ggplot(mapping = aes_string(x = fct_infreq(data[,i]),
                                     fill = data[,i])) +
    geom_bar(width = 1, colour = "black", show.legend = F,
             aes(y = ((..count..)/sum(..count..)))) +
    geom_text(aes(y = ((..count..)/sum(..count..)),
                  label = scales::percent((..count..)/sum(..count..))),
              stat = "count", size=4, vjust = -.3) +
    scale_y_continuous(labels = scales::percent) +
    theme + labs(x = "", y = "Pourcentage", caption = tag_source) +
    ggtitle(str_replace_all(str_to_title(i), c("_" = " ")))
  print(plot)
}

names(data) <- names
```

### Density and log of continuous variables

```{r cache=TRUE,include=T,message=FALSE, warning=FALSE, echo=T}
names <- names(data)

data <- data %>% rename(prix = price)

features_numeric <- names(select_if(data[,-c(1,6:7)],is.numeric))
# Without id, latitude and longitude

for (i in features_numeric){

  plot <- ggplot(mapping = aes(x = data[,i])) +
    geom_histogram(colour="black", fill="dodgerblue3",
                   aes(y = ..density..)) + theme + 
    ggtitle(str_replace_all(str_to_title(i), c("_" = " "))) +
    labs(x = "", y = "Densité", caption = tag_source) +
    geom_density(fill = "cyan", colour = "cyan",
                 alpha = 0.5, lwd=0.5, linetype = "dashed")

  log_plot <- ggplot(mapping = aes(x = log(data[,i]))) +
    geom_histogram(colour="black", fill="forestgreen",
                   aes(y= ..density..)) + theme +
    labs(x = "", y = "Densité", caption = tag_source) +
    ggtitle(str_replace_all(paste("Log de",str_to_title(i)), 
                            c("_" = " "))) +
    geom_density(fill = "olivedrab2", colour = "olivedrab2",
                 alpha = 0.5, lwd=0.5, linetype = "dashed")

  grid.arrange(plot, log_plot, ncol=2)
}

names(data) <- names
```

### Boxplot 

```{r cache=TRUE,include=T,message=FALSE, warning=FALSE, echo=T}
# # ===== ===== Prix par arrondissement ===== =====
ggplot(data, aes(x = neighbourhood_group_cleansed, y = log(price))) +
  geom_boxplot(outlier.colour = "darkblue", outlier.size = 0.5,
               color="deepskyblue", fill="cyan", alpha=0.2) +
  ggtitle("Prix des airbnb par nuit en moyenne (en log) par arondissement") +
  labs(x = "Arrondissements", y = "Prix par nuit en moyenne (en log)",
       caption = tag_source) + theme

# # ===== ===== Prix par arrondissement et type de logement ===== =====

ggplot(data, aes(x = neighbourhood_group_cleansed, y = log(price),
                 fill = property_type)) +
  geom_boxplot(outlier.colour = "darkblue", outlier.size = 0.5) +
  ggtitle("Prix des airbnb par nuit en moyenne (en log)
          par arondissement et par type de logement") +
  scale_fill_discrete(name = "Type de logement") + theme +
  labs(x = "Arrondissement", y = "Prix par nuit en moyenne (en log)",
       caption = tag_source)

# # ===== ===== Répartition des logements par arrondissement ===== =====

ggplot(data, aes(x = neighbourhood_group_cleansed, 
                 group = property_type)) +
  geom_bar(aes(y = ..prop.., 
               fill = factor(..x.., labels = c('Bronx','Brooklyn','Manhattan',
                              "Queens","Staten Island"))), stat="count") +
  geom_text(aes(label = scales::percent(..prop..),
                y= ..prop.. ), stat= "count", vjust = -.4, size=2) +
  facet_grid(~property_type) +
  scale_y_continuous(labels = scales::percent) +
  ggtitle("Répartition des arrondissement par logements") + 
  theme(plot.title = element_text(hjust = 0.5),
        plot.background = element_rect(fill = "#BFD5E3"),
        axis.text.x=element_blank(), axis.ticks.x=element_blank()) +
  labs(x = "", y = "", caption = tag_source, fill = "Arrondissement") +
  scale_color_discrete()

ggplot(data, aes(x = property_type, 
                 group = neighbourhood_group_cleansed)) +
  geom_bar(aes(y = ..prop.., 
               fill = factor(..x.., labels = c('Appartment','House',
                                               'Private Room',"Shared Room"))),
           stat="count") +
  geom_text(aes(label = scales::percent(..prop..),
                y= ..prop.. ), 
            stat= "count", vjust = -.5, hjust = 0.1, size=2) +
  facet_grid(~neighbourhood_group_cleansed) +
  scale_y_continuous(labels = scales::percent) +
  ggtitle("Répartition des logements par arrondissement") + 
  theme(plot.title = element_text(hjust = 0.5),
        plot.background = element_rect(fill = "#BFD5E3"),
        axis.text.x=element_blank(), axis.ticks.x=element_blank()) +
  labs(x = "", y = "", caption = tag_source, fill = "Type de propriété") +
  scale_color_discrete()
```

### Correlation matrix

```{r cache=TRUE,include=T,message=FALSE, warning=FALSE, echo=T, eval=F}
my_fn <- function(data, mapping, method="p", use="pairwise", ...) {
  x <- eval_data_col(data, mapping$x)
  y <- eval_data_col(data, mapping$y)
  corr <- cor(x, y, method=method, use=use)
  colFn <- colorRampPalette(c("blue", "white", "red"), 
                            interpolate ='spline')
  fill <- colFn(100)[findInterval(corr, seq(-1, 1, length=100))]
  ggally_cor(data = data, mapping = mapping, ...) + 
    theme_void() + theme(panel.background = element_rect(fill=fill))
  }

ggpairs(data[,features_numeric], 
        upper = list(continuous = my_fn), lower = "blank") + 
  theme(plot.title = element_text(hjust = 0.5),
        plot.background = element_rect(fill = "#BFD5E3"),
        axis.text.x=element_blank(), axis.ticks.x=element_blank(),
        axis.text.y=element_blank(), axis.ticks.y=element_blank()) + 
  labs(caption = tag_source) +
  ggtitle("Matrice de corrélation des variables continues")
```

### Spatial Heatmap

```{r cache=TRUE,include=F,message=FALSE, warning=FALSE, echo=T}
height <- max(data$latitude) - min(data$latitude)
width <- max(data$longitude) - min(data$longitude)
borders <- c(bottom  = min(data$latitude)  - 0.1 * height,
             top     = max(data$latitude)  + 0.1 * height,
             left    = min(data$longitude) - 0.1 * width,
             right   = max(data$longitude) + 0.1 * width)

map <- get_stamenmap(borders, zoom = 11, maptype = "terrain")
```

#### Evolution des prix par quartier

```{r cache=TRUE,include=F,message=FALSE, warning=FALSE, echo=T}
by_neighbourhood <- group_by(data, neighbourhood_cleansed) %>%
  summarize(longitude = median(longitude),
            latitude = median(latitude),
            prix_median = median(price),
            prix_moyen = mean(price),
            scores_moyen = mean(review_scores_rating))

for (i in by_neighbourhood$neighbourhood_cleansed) {
  for (j in data$neighbourhood_cleansed) {
    if (i == j) {
      a <- unique(as.character(data[data$neighbourhood_cleansed==j,
                                   "neighbourhood_group_cleansed"]))
      by_neighbourhood[by_neighbourhood$neighbourhood_cleansed==i,
                       "neighbourhood_group_cleansed"] <- a
    }
  }
}

by_neighbourhood$neighbourhood_group_cleansed <-
  as.factor(by_neighbourhood$neighbourhood_group_cleansed)
```

```{r cache=TRUE,include=T,message=FALSE, warning=FALSE, echo=T}
# # ===== ===== Prix moyen par quartiers ===== =====
ggmap(map) +
  geom_point(by_neighbourhood,
             mapping = aes(x = longitude, y = latitude,
                           col = prix_moyen,
                           shape = neighbourhood_group_cleansed)) +
  scale_colour_gradient(low = "blue", high = "red") + theme +
  labs(x = "", y = "", caption = tag_source, 
       col = "Prix moyen", shape = "Arrondissement") +
  ggtitle("Prix moyen par quartier")
```

#### Evolution des prix par Arrondissement

```{r cache=TRUE,include=F,message=FALSE, warning=FALSE, echo=T}
by_borough <- group_by(data, neighbourhood_group_cleansed) %>%
  summarize(longitude = median(longitude),
            latitude = median(latitude),
            prix_moyen = mean(price),
            prix_median = median(price),
            scores_moyen = mean(review_scores_rating),
            disponibilité_moyen = mean(availability_365))
```

```{r cache=TRUE,include=T,message=FALSE, warning=FALSE, echo=T}
# # ===== ===== Prix moyen par arrondissements ===== =====
ggmap(map) +
  geom_point(by_borough, shape = 18,
             mapping = aes(x = longitude, y = latitude,
                           col = prix_moyen, size = disponibilité_moyen)) +
  scale_colour_gradient(low = "blue", high = "red") +
  theme + labs(x = "", y = "", caption = tag_source,
               size = "Disponibilité annuel moyen",
               col = "Prix moyen") +
  ggtitle("Prix moyen et disponibilité par arrondissements") +
  geom_label(by_borough,
             mapping = aes(longitude, latitude,
                           label = neighbourhood_group_cleansed),
             size = 1.5, fontface = "bold",
             nudge_x = 0.015, nudge_y = -0.03)
```

# Models

### Setting up the theme

```{r cache=TRUE,include=F,message=FALSE, warning=FALSE, echo=T}
theme_models <- theme(plot.title = element_text(hjust = 0.5),
               plot.background = element_rect(fill = "#BFD5E3"),
               legend.position = "none")

tag_source_models <- "The model has been fit using 62762 samples & 18 predictor (with constant)
and the dependant variable was the log of price"
```

### Split the data and setting seeds

```{r cache=TRUE,include=F,message=FALSE, warning=FALSE, echo=T}
# # ===== Create a subset of the data to use in prediction ===== =====

data_model <- data %>% select(-c("id", "neighbourhood_cleansed", 
                                 "latitude", "longitude", "price"))
data_model$log_price <- log(data$price)

# # ===== Create dummy variables =====

dummies <- dummyVars(log_price~., data_model, sep = "_")
new_set <- as.data.frame(predict(dummies, newdata = data_model))
data_model <- cbind(new_set,data_model$log_price)
colnames(data_model)[which(names(data_model) == "data_model$log_price")] <- "log_price"

# # ===== ===== Train / Test split ===== =====
set.seed(777)

trainIndex <- createDataPartition(data_model$log_price, 
                                  p = .8, 
                                  list = FALSE, 
                                  times = 1)

data_train <- data_model[trainIndex,]
data_test  <- data_model[-trainIndex,]

# # ===== ===== Setting up the validation methods ===== =====

# function to set up random seeds
setSeeds <- function(method = "cv", numbers = 1, repeats = 1, tunes = NULL, seed = 1237) {
  #B is the number of resamples and integer vector of M (numbers + tune length if any)
  B <- if (method == "cv") numbers
  else if(method == "repeatedcv") numbers * repeats
  else NULL
  
  if(is.null(length)) {
    seeds <- NULL
  } else {
    set.seed(seed = seed)
    seeds <- vector(mode = "list", length = B)
    seeds <- lapply(seeds, function(x) sample.int(n = 1000000, size = numbers + ifelse(is.null(tunes), 0, tunes)))
    seeds[[length(seeds) + 1]] <- sample.int(n = 1000000, size = 1)
  }
  # return seeds
  seeds
}

rcvSeeds <- setSeeds(method = "repeatedcv", 
                      numbers = 5, repeats = 5, 
                      tunes = 100, seed = 777)

K5_CV_seed <- trainControl(method = "cv", number = 5, classProbs = TRUE, 
                           savePredictions = TRUE, seeds = rcvSeeds)
```

### Allow for Parallel computing

```{r cache=TRUE,include=F,message=FALSE, warning=FALSE, echo=T}
registerDoMC(cores = 3)
```

## Ordinary Least Square model 

```{r cache=TRUE,include=T,message=FALSE, warning=FALSE, echo=T}
set.seed(777)

ols_fit <- train(log_price ~ . - 
                   host_is_superhost_False -
                   property_type_SharedRoom -
                   neighbourhood_group_cleansed_Queens -
                   cancellation_policy_moderate, 
                 data = data_train, 
                 method = "lm" , 
                 trControl = K5_CV_seed)

summary(ols_fit)

ols_pred <- predict(ols_fit, data_test)

postResample(pred = ols_pred, obs = data_test$log_price)
```

```{r cache=TRUE,include=T,message=FALSE, warning=FALSE, echo=T}
ols_varImp <- data.frame(variables = row.names(varImp(ols_fit)$importance),
                         varImp(ols_fit)$importance)

ggplot(data = ols_varImp, mapping = aes(x=reorder(variables, Overall),
                                        y=Overall,
                                        fill=variables)) +
  coord_flip() + geom_bar(stat = "identity", position = "dodge") +
  theme_models + labs(x = "", y = "", caption = tag_source_models) +
  ggtitle("OLS: Variables d'importances") 
```

## Ridge regression

```{r cache=TRUE,include=T,message=FALSE, warning=FALSE, echo=T}
set.seed(777)

ridge_fit <- train(log_price ~ . - 
                     host_is_superhost_False -
                     property_type_SharedRoom -
                     neighbourhood_group_cleansed_Queens -
                     cancellation_policy_moderate, 
                   data = data_train, 
                   method = "glmnet",
                   tuneGrid = expand.grid(alpha = 0, 
                                          lambda = seq(0, 1, 0.01)),
                   preProcess = c("scale","center"),
                   trControl = K5_CV_seed)

ridge_fit$bestTune

ridge_pred <- predict(ridge_fit, data_test)

postResample(pred = ridge_pred, obs = data_test$log_price)
```

```{r cache=TRUE,include=T,message=FALSE, warning=FALSE, echo=T}
ridge_varImp <- data.frame(variables = row.names(varImp(ridge_fit)$importance),
                           varImp(ridge_fit)$importance)

ggplot(data = ridge_varImp, mapping = aes(x=reorder(variables, Overall),
                                        y=Overall,
                                        fill=variables)) +
  coord_flip() + geom_bar(stat = "identity", position = "dodge") +
  theme_models + labs(x = "", y = "", caption = tag_source_models) +
  ggtitle("Ridge regression: Variables d'importances") 
```

## Lasso regression

```{r cache=TRUE,include=T,message=FALSE, warning=FALSE, echo=T}
set.seed(777)

lasso_fit <- train(log_price ~ . - 
                     host_is_superhost_False -
                     property_type_SharedRoom -
                     neighbourhood_group_cleansed_Queens -
                     cancellation_policy_moderate,  
                   data = data_train, 
                   method = "glmnet",
                   tuneGrid = expand.grid(alpha = 1, 
                                          lambda = seq(0, 1, 0.01)),
                   preProcess = c("scale","center"),
                   trControl = K5_CV_seed)

lasso_fit$bestTune

lasso_pred <- predict(lasso_fit, data_test)

postResample(pred = lasso_pred, obs = data_test$log_price)
```

```{r cache=TRUE,include=T,message=FALSE, warning=FALSE, echo=T}
lasso_varImp <- data.frame(variables = row.names(varImp(lasso_fit)$importance),
                           varImp(lasso_fit)$importance)

ggplot(data = lasso_varImp, mapping = aes(x=reorder(variables, Overall),
                                        y=Overall,
                                        fill=variables)) +
  coord_flip() + geom_bar(stat = "identity", position = "dodge") +
  theme_models + labs(x = "", y = "", caption = tag_source_models) +
  ggtitle("Lasso regression: Variables d'importances") 
```

## Polynomial Models 

### Polynomial plots

```{r cache=TRUE,include=T,message=FALSE, warning=FALSE, echo=T}
set.seed(777)

# We choose the number of maximum polynomial degree
max_degree <- 5

list <- c("bedrooms","minimum_nights","accommodates",
          "cleaning_fee","availability_365","beds")

for (l in list){
  RMSE <- rep(0,max_degree)
  for (d in 1:max_degree) {
    PolyRegressor <- train(as.formula(bquote(log_price ~ poly(.(as.name(l)), .(d)))),
                           data = data_train,
                           method = "lm",
                           trControl = K5_CV_seed)
    RMSE[d]<- PolyRegressor$results$RMSE
  }
  tem_data = data.frame(1:max_degree, RMSE)
  plot <- ggplot(aes(x = 1:max_degree,y = RMSE), data = tem_data) +
    geom_line(col="red") + theme_models +
    labs(x = "Polynomial Degrees", y = "RMSE",
         caption = "The model has been fit using 62942 samples and 1 predictor.
         The dependant variable was the log of price") +
    ggtitle(paste(l,"RMSE by polynomial degrees"))
  print(plot)
}
```

### Polynomial Regression

```{r cache=TRUE,include=T,message=FALSE, warning=FALSE, echo=T}
set.seed(777)

poly_fit <- train(log_price ~ poly(accommodates,3) + 
                    poly(availability_365,3) +
                    poly(bedrooms,4) + 
                    poly(cleaning_fee,5) +. - 
                    host_is_superhost_False -
                    property_type_SharedRoom -
                    neighbourhood_group_cleansed_Queens -
                    cancellation_policy_moderate -
                    accommodates -
                    availability_365 -
                    bedrooms -
                    cleaning_fee,
                  data = data_train, 
                  method = "lm" , 
                  trControl = K5_CV_seed)

summary(poly_fit)

poly_pred <- predict(poly_fit, data_test)

postResample(pred = poly_pred, obs = data_test$log_price)

# RMSE 0.5016245
```

```{r cache=TRUE,include=T,message=FALSE, warning=FALSE, echo=T}
poly_varImp <- data.frame(variables = row.names(varImp(poly_fit)$importance),
                          varImp(poly_fit)$importance)

ggplot(data = poly_varImp, mapping = aes(x=reorder(variables, Overall),
                                         y=Overall,
                                         fill=variables)) +
  coord_flip() + geom_bar(stat = "identity", position = "dodge") +
  theme_models + 
  labs(x = "", y = "", 
       caption = "The model has been fit using 62762 samples & 23 predictor (with constant) and the dependant variable was the log of price.
       The variable bedrooms was taken to the 4th polynomial degree, the variable availability_365 was taken to the 
       3rd polynomial degree and the variable bedrooms was taken to the 2nd polynomial degree.") +
  ggtitle("Polynomial regression: Variables d'importances") 
```

## KNN

### PreProcess / Standardize

```{r cache=TRUE,include=F,message=FALSE, warning=FALSE, echo=T}
#Train
Preproc_train <- preProcess(data_train[,c("accommodates","beds","bedrooms",
                                          "cleaning_fee","minimum_nights",
                                          "availability_365",
                                          "review_scores_rating")],
                            method=c('center','scale'))

data_train_standardized <- predict(Preproc_train,data_train)

#Test
Preproc_test <- preProcess(data_test[,c("accommodates","beds","bedrooms",
                                        "cleaning_fee","minimum_nights",
                                        "availability_365",
                                        "review_scores_rating")],
                            method=c('center','scale'))

data_test_standardized <- predict(Preproc_test, data_test)
```

### KNN Regression

```{r cache=TRUE,include=F,message=FALSE, warning=FALSE, echo=T}
set.seed(777)

# Grid <- expand.grid(k = seq(15,20,1))
Grid <- expand.grid(k = 19)

knn_fit <- train(log_price ~., 
                 data = data_train_standardized,
                 method = "knn",
                 trControl = K5_CV_seed,
                 tuneGrid = Grid,
                 allowParallel = TRUE)

# plot(knn_fit)
# knn_fit$bestTune

knn_pred <- predict(knn_fit, data_test_standardized)
 
postResample(pred = knn_pred, obs = data_test_standardized$log_price)

#      RMSE  Rsquared       MAE 
# 0.4726992 0.5726099 0.3493219 
```

```{r cache=TRUE,include=T,message=FALSE, warning=FALSE, echo=T}
knn_varImp <- data.frame(variables = row.names(varImp(knn_fit)$importance),
                          varImp(knn_fit)$importance)

ggplot(data = knn_varImp, mapping = aes(x=reorder(variables, Overall),
                                         y=Overall,
                                         fill=variables)) +
  coord_flip() + geom_bar(stat = "identity", position = "dodge") +
  theme_models + labs(x = "", y = "") +
  ggtitle("K nearest neighhbor: Variables d'importances") 
```

## Boosting 

```{r cache=TRUE,include=F,message=FALSE, warning=FALSE, echo=T}
# Grid <- expand.grid(n.trees = seq(100,400,50),
#                     interaction.depth = seq(2,4,1),
#                     shrinkage = seq(0.07,0.15,0.01),
#                     n.minobsinnode= seq(2,4,1))

Grid <- expand.grid(n.trees = 300,
                    interaction.depth = 2,
                    shrinkage = 0.1,
                    n.minobsinnode= 3)

set.seed(777)
gbm_fit  <-  train(log_price~., 
                   data = data_train,  
                   method = "gbm", 
                   bag.fraction = 0.5, 
                   distribution = "gaussian",
                   trControl = K5_CV_seed, 
                   tuneGrid = Grid)

# plot(gbm_fit)
# gbm_fit$bestTune

gbm_pred <- predict(gbm_fit, data_test)

#RMSE for BoostingTrees
postResample(pred = gbm_pred, obs = data_test$log_price)

#      RMSE  Rsquared       MAE 
# 4647998 0.5868486 0.3437535 
```


## XGboost

```{r cache=TRUE,include=T,message=FALSE, warning=FALSE, echo=T}
# Grid <- expand.grid(nrounds = 0:50,
#                       max_depth = 5,
#                       eta = 0.3,
#                       gamma = 0.01,
#                       colsample_bytree = 0.5,
#                       min_child_weight = 0,
#                       subsample = 0.5)

Grid <- expand.grid(nrounds = 47,
                    max_depth = 5,
                    eta = 0.3,
                    gamma = 0.01,
                    colsample_bytree = 0.5,
                    min_child_weight = 0,
                    subsample = 0.5)

set.seed(777)
xgboost_fit  <-  train(log_price~., 
                       data = data_train,  
                       method = "xgbTree", 
                       bag.fraction = 0.5, 
                       trControl = K5_CV_seed, 
                       tuneGrid = Grid,
                       allowParallel = TRUE)

# plot(xgboost_fit)
# xgboost_fit$bestTune

xgboost_pred <- predict(xgboost_fit, data_test)

#RMSE for BoostingTrees
postResample(pred = xgboost_pred, obs = data_test$log_price)

#      RMSE  Rsquared       MAE 
# 0.4524891 0.6083713 0.3340023 
```

```{r cache=TRUE,include=T,message=FALSE, warning=FALSE, echo=T}
xgboost_varImp <- data.frame(variables = row.names(varImp(xgboost_fit)$importance),
                             varImp(xgboost_fit)$importance)

ggplot(data = xgboost_varImp, mapping = aes(x=reorder(variables, Overall),
                                            y=Overall, fill=variables)) +
  coord_flip() + geom_bar(stat = "identity", position = "dodge") +
  theme(plot.title = element_text(hjust = 0.5),
               plot.background = element_rect(fill = "#BFD5E3"),
               legend.position = "none") + 
  labs(x = "", y = "", caption = tag_source_models) +
  ggtitle("XGBoost: Variables d'importances") 
```

## Random forest

```{r cache=TRUE,include=T,message=FALSE, warning=FALSE, echo=T}
# Grid <- expand.grid(.mtry=c(1:5))
Grid <- expand.grid(.mtry=5)

set.seed(777)
rf_fit  <-  train(log_price ~ .,
                  data = data_train,
                  method = "rf",
                  trControl = K5_CV_seed, 
                  tuneGrid = Grid,
                  allowParallel = TRUE)

# plot(rf_fit)
# rf_fit$bestTune

rf_pred <- predict(rf_fit, newdata = data_test)

#RMSE for Random Forest
postResample(pred = rf_pred, obs = data_test$log_price)

#      RMSE  Rsquared       MAE 
# 0.4418751 0.6271526 0.3233835 
```

## Comparaison of models (Train set)

### RMSE and R2 based on Train set

```{r cache=TRUE,include=T,message=FALSE, warning=FALSE, echo=T}
models <- list(Linear = ols_fit, 
               Ridge = ridge_fit, 
               Polynomial = poly_fit,
               KNN =  knn_fit, 
               Boosting = gbm_fit, 
               XGBoost = xgboost_fit,
               RForest = rf_fit)
res <- resamples(models)

models_list = c("Linear", "Ridge", "Polynomial", "KNN",
                "Boosting", "XGBoost", "RForest")

df = data.frame()
for (i in models_list){
  x = data.frame (model = i, 
                  RMSE = res$values[paste(i,"RMSE", sep = "~")],
                  Rsquared = res$values[paste(i,"Rsquared", sep = "~")])
  x <- x %>% rename(RMSE = paste(i,".RMSE", sep = ""))
  x <- x %>% rename(Rsquared = paste(i,".Rsquared", sep = ""))
  df <- rbind(df,x)
}

df$Category <- factor(ifelse(df$model %in% c("KNN", "Boosting", "XGBoost", 
                                             "RForest"), 1, 0), 
                      labels = c("Parametric", "Non-Parametric"))

theme_models2 <- theme(plot.title = element_text(hjust = 0.5),
               plot.background = element_rect(fill = "#BFD5E3"))

# RMSE 
ggplot(data = df, aes(x = fct_reorder(model, RMSE, .desc = T), 
                      y = RMSE, fill = Category)) +
  geom_boxplot(outlier.colour = "darkblue", outlier.size = 2, alpha=0.2) +
  theme_models2 + 
  labs(x = "", y = "RMSE", 
       caption = "All the models were fit using the train set with 62762 observations and 21 variables.
       The validation methode chosen was a 5 Fold Cross Validation") +
  ggtitle("Models Performances by RMSE (based on train set)") +
  scale_fill_manual(values=c("blue3", "green3"))

# Rsquared
ggplot(data = df, aes(x = fct_reorder(model, Rsquared, .desc = F), 
                      y = Rsquared, fill = Category)) +
  geom_boxplot(outlier.colour = "darkblue", outlier.size = 2, alpha=0.2) +
  theme_models2 + 
  labs(x = "", y = "Rsquared", 
       caption = "All the models were fit using the Train set with 62762 observations and 21 variables. 
       The validation methode chosen was a 5 Fold Cross Validation") +
  ggtitle("Models Performances by Rsquared (based on Train set)") +
  scale_fill_manual(values=c("blue3", "green3"))
```

## Comparaison of models (Test set)

```{r cache=TRUE,include=T,message=FALSE, warning=FALSE, echo=T}
pred_list = c("ols_pred", "ridge_pred", "poly_pred", "knn_pred", 
                "gbm_pred", "xgboost_pred", "rf_pred")

models_list = c("OLS", "Ridge", "Polynomial", "KNN",
                "Boosting", "XGBoost", "RForest")

df = data.frame()
for (i in pred_list){
  if (i == "knn_pred"){
    x = as.data.frame(postResample(pred = get(i), 
                                   obs = data_test_standardized$log_price))
    names(x)[1] <- i
    x <- t(x)
  }
  else {
    x = as.data.frame(postResample(pred = get(i), obs = data_test$log_price)) 
    names(x)[1] <- i
    x <- t(x)
  }
  df <- rbind(df,x)
}

df$model <- models_list

df$Category <- factor(ifelse(df$model %in% c("KNN", "Boosting", "XGBoost", 
                                             "RForest"), 1, 0), 
                      labels = c("Linear", "Non-Linear"))

# RMSE 
ggplot(data = df, aes(x = fct_reorder(model, RMSE, .desc = T), 
                      y = RMSE, fill = Category)) +
  geom_bar(stat = "identity", alpha=0.5) + theme_models2 +
  labs(x = "", y = "RMSE",
       caption = "All the models were fit using the Test set with 15689 observations and 21 variables.
       The validation methode chosen was a 5 Fold Cross Validation") +
  ggtitle("Models Performances by RMSE (based on Test set)") +
  scale_fill_manual(values=c("blue3", "green3"))

# Rsquared 
ggplot(data = df, aes(x = fct_reorder(model, Rsquared, .desc = F), 
                      y = Rsquared, fill = Category)) +
  geom_bar(stat = "identity", alpha=0.5) + theme_models2 +
  labs(x = "", y = "Rsquared",
       caption = "All the models were fit using the Test set with 15689 observations and 21 variables.
       The validation methode chosen was a 5 Fold Cross Validation") +
  ggtitle("Models Performances by Rsquared (based on Test set)") +
  scale_fill_manual(values=c("blue3", "green3"))
```

```{r cache=TRUE,include=T,message=FALSE, warning=FALSE, echo=T}
rf_varImp <- data.frame(variables = row.names(varImp(rf_fit)$importance),
                        varImp(rf_fit)$importance) 

ggplot(data = rf_varImp, mapping = aes(x=reorder(variables, Overall),
                                         y=Overall,
                                         fill=variables)) +
  coord_flip() + geom_bar(stat = "identity", position = "dodge") +
  theme(plot.title = element_text(hjust = 0.5),
               plot.background = element_rect(fill = "#BFD5E3"),
               legend.position = "none") + 
  labs(x = "", y = "", caption = tag_source_models) +
  ggtitle("Random Forest: Variables d'importances") 
```


## Prediction vs Actual

```{r cache=TRUE,include=T,message=FALSE, warning=FALSE, echo=T}
results <- as.data.frame (cbind (exp(data_test$log_price), exp(xgboost_pred)))
results <- results %>% rename (Actuals = V1,
                   Predictions = V2)
results$Gap <- abs(results$Actuals - results$Predictions)
head (results)
summary(results$Gap)
```

